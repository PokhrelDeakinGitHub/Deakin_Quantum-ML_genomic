{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetslovely/QML_genom/blob/main/QSVC_Pauli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "fmTDXZE6BBBG",
        "outputId": "fc3a484f-5ff5-44d8-db39-9a3fc5bbece8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-812fc49640b8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install qiskit-machine-learning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install qiskit[visualization]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom\n",
        "!pip install qiskit-machine-learning\n",
        "!pip install qiskit[visualization]\n",
        "!pip install genomic-benchmarks\n",
        "!pip install tensorflow>=2.6.0\n",
        "!pip install tensorflow-addons\n",
        "!pip install typing-extensions --upgrade\n",
        "!pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ga_BACqBKiQ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "from genomic_benchmarks.loc2seq import download_dataset\n",
        "from genomic_benchmarks.data_check import is_downloaded, info\n",
        "from genomic_benchmarks.models.tf import vectorize_layer\n",
        "from genomic_benchmarks.models.tf import get_basic_cnn_model_v0 as get_model\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes,ZFeatureMap, PauliFeatureMap\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "from functools import partial\n",
        "# from qiskit import Aer\n",
        "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
        "from qiskit.primitives import Sampler\n",
        "import pickle\n",
        "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
        "from qiskit_machine_learning.algorithms import PegasosQSVC\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from qiskit import ClassicalRegister, QuantumRegister\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import RealAmplitudes\n",
        "from qiskit.quantum_info import Statevector\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_algorithms.utils import algorithm_globals\n",
        "\n",
        "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from sklearn.decomposition import PCA\n",
        "algorithm_globals.random_seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn7WWj9RCyVl"
      },
      "outputs": [],
      "source": [
        "# Load the preprocessed data\n",
        "train_sequences = np.load('train_sequences.npy')\n",
        "# print('train_sequences',train_sequences[:2])\n",
        "train_labels = np.load('train_labels.npy')\n",
        "# print('train_labels',train_labels[:2])\n",
        "test_sequences = np.load('test_sequences.npy')\n",
        "# print('test_sequences',test_sequences[:2])\n",
        "test_labels = np.load('test_labels.npy')\n",
        "# print('test_labels',test_labels[:2])\n",
        "# Perform PCA transformation on the data\n",
        "pca = PCA(n_components=4)\n",
        "train_sequences = pca.fit_transform(train_sequences)\n",
        "test_sequences= pca.fit_transform(test_sequences)\n",
        "\n",
        "# Split the train_sequences, train_labels, test_sequences, and test_labels into 15 parts each\n",
        "split_train_sequences = np.array_split(train_sequences, 15)\n",
        "split_train_labels = np.array_split(train_labels, 15)\n",
        "split_test_sequences = np.array_split(test_sequences, 15)\n",
        "split_test_labels = np.array_split(test_labels, 15)\n",
        "\n",
        "# Create directories to save the parts\n",
        "os.makedirs('/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/train_sequences_parts', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/train_labels_parts', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/test_sequences_parts', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/test_labels_parts', exist_ok=True)\n",
        "\n",
        "# Save each part into a separate file\n",
        "for i in range(15):\n",
        "    np.save(f'/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/train_sequences_parts/train_seq_{i+1}.npy', split_train_sequences[i])\n",
        "    np.save(f'/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/train_labels_parts/train_labels_{i+1}.npy', split_train_labels[i])\n",
        "    np.save(f'/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/test_sequences_parts/test_seq_{i+1}.npy', split_test_sequences[i])\n",
        "    np.save(f'/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/test_labels_parts/test_labels_{i+1}.npy', split_test_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vRR3St-C1zp"
      },
      "outputs": [],
      "source": [
        "# Define the feature dimension or number of qubits\n",
        "feature_dim = len(train_sequences[0])\n",
        "print(\"Feature dimension and number of qubits:\", feature_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Bbg4W5wC2ov"
      },
      "outputs": [],
      "source": [
        "from qiskit_algorithms.state_fidelities import ComputeUncompute\n",
        "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
        "from qiskit_machine_learning.algorithms import QSVC\n",
        "\n",
        "feature_dim = len(train_sequences[0])\n",
        "feature_map = PauliFeatureMap(feature_dim, reps=2)\n",
        "sampler = Sampler()\n",
        "fidelity = ComputeUncompute(sampler=sampler)\n",
        "qkernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
        "qsvc = QSVC(kernel=qkernel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f9t5a-LC-xU"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1  # Specify the number of epochs\n",
        "batch_size = 1024  # Specify the batch size\n",
        "total_time = 0\n",
        "\n",
        "# Placeholder for saving scores\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "all_part_scores = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpWS727ease6"
      },
      "outputs": [],
      "source": [
        "qsvc.load(\"/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QSVC_PauliFeatureMap_after_part_1_epoch_1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOZgXjWZDC6L"
      },
      "outputs": [],
      "source": [
        "# num_epochs = 10  # Specify the number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()  # Start time for the epoch\n",
        "    epoch_train_scores = []  # Store training scores for each epoch\n",
        "\n",
        "    # Loop over each data split\n",
        "    for a in range(2, 5):\n",
        "        # Load the split data\n",
        "        train_sequences_part = np.load(f'/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/train_sequences_parts/train_seq_{a}.npy')\n",
        "        train_labels_part = np.load(f'/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/train_labels_parts/train_labels_{a}.npy')\n",
        "\n",
        "        print(f\"Training on part {a} started\")\n",
        "\n",
        "        # Perform training for each batch\n",
        "        for i in range(0, len(train_sequences_part), batch_size):\n",
        "            batch_sequences = train_sequences_part[i:i+batch_size]\n",
        "            batch_labels = train_labels_part[i:i+batch_size]\n",
        "\n",
        "            # Fit the model on the batch\n",
        "            qsvc.fit(batch_sequences, batch_labels)\n",
        "\n",
        "            # # Optionally evaluate on training data\n",
        "            # score = qsvc.score(batch_sequences, batch_labels)\n",
        "            # epoch_train_scores.append(score)\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}, Part {a} - Batch {i // batch_size + 1} completed\")\n",
        "\n",
        "        # Optionally, save the model after each part is processed within an epoch\n",
        "        qsvc.save(f'QSVC_PauliFeatureMap_after_part_{a}_epoch_{epoch+1}')\n",
        "        print(f\"Model saved after part {a}, epoch {epoch+1} completed\")\n",
        "        with open(f'QSVC_PauliFeatureMap_after_part_{a}_epoch_{epoch+1}.pkl', 'wb') as f:\n",
        "            pickle.dump(qsvc, f)\n",
        "        print(f\"Pickle Model saved after part {a}, epoch {epoch+1} completed\")\n",
        "\n",
        "        # # File path for training scores\n",
        "        # part_scores_file = f'QSVC_ZFeatureMap_train_scores_part_{a}_epoch_{epoch+1}.npy'\n",
        "\n",
        "        # # Check if the file exists and append if it does\n",
        "        # if os.path.exists(part_scores_file):\n",
        "        #     existing_scores = np.load(part_scores_file)\n",
        "        #     updated_scores = np.concatenate((existing_scores, np.array(epoch_train_scores)))\n",
        "        #     np.save(part_scores_file, updated_scores)\n",
        "        #     print(f\"Scores appended to file {part_scores_file}\")\n",
        "        # else:\n",
        "\n",
        "        #     np.save(part_scores_file, np.array(epoch_train_scores))\n",
        "\n",
        "    # Average training score for the epoch\n",
        "    # epoch_train_scores = np.load(f'/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QML_genom_seq/train_sequences_parts/train_seq_{a}.npy')\n",
        "\n",
        "    # for a in range(1, 5):\n",
        "    #     part_scores_file = f'QSVC_ZFeatureMap_train_scores_part_{a}_epoch_{epoch+1}.npy'\n",
        "    #     if os.path.exists(part_scores_file):\n",
        "    #         # Load the scores from file\n",
        "    #         part_scores = np.load(f'/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/{part_scores_file}')\n",
        "    #         # Calculate the average score for this part\n",
        "    #         average_part_score = np.mean(part_scores)\n",
        "    #         all_part_scores.append(average_part_score)\n",
        "    #         print(f\"Average score for part {a} in epoch {epoch+1}: {average_part_score:.4f}\")\n",
        "\n",
        "    # # Average training score for the epoch\n",
        "    # average_train_score = np.mean(all_part_scores)\n",
        "    # train_scores.append(average_train_score)\n",
        "\n",
        "    # # Evaluate on the entire test dataset after each epoch\n",
        "    # test_score = qsvc.score(test_sequences[:4000], test_labels[:4000])\n",
        "    # test_scores.append(test_score)\n",
        "\n",
        "    # print(f\"Epoch {epoch+1} - Training Score: {average_train_score:.4f}, Test Score: {test_score:.4f}\")\n",
        "\n",
        "    qsvc.save(f'QSVC_PauliFeatureMap_epoch_{epoch+1}')\n",
        "    print(f\"Model saved after epoch {epoch+1} completed\")\n",
        "    # Save the model using pickle\n",
        "    with open(f'QSVC_PauliFeatureMap_epoch_{epoch+1}.pkl', 'wb') as f:\n",
        "        pickle.dump(qsvc, f)\n",
        "    print(f\"Model saved after pickle epoch {epoch+1} completed\")\n",
        "\n",
        "    # Calculate the time for the epoch\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "    total_time += epoch_time\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Time taken: {epoch_time:.2f} seconds\")\n",
        "\n",
        "print(f\"Total training time: {total_time:.2f} seconds\")\n",
        "\n",
        "# # Save scores to a file for later use\n",
        "# # np.save('Pegaos_QSVM_train_scores_ZFeatureMap.npy', np.array(train_scores))\n",
        "# # np.save('Pegaos_QSVM_test_scores_ZFeatureMap.npy', np.array(test_scores))\n",
        "\n",
        "# train_scores_file = 'QSVC_train_scores_ZFeatureMap.npy'\n",
        "# test_scores_file = 'QSVC_train_scores_ZFeatureMap.npy'\n",
        "\n",
        "# if os.path.exists(train_scores_file):\n",
        "#     existing_train_scores = np.load(train_scores_file)\n",
        "#     updated_train_scores = np.concatenate((existing_train_scores, train_scores))\n",
        "#     np.save(train_scores_file, updated_train_scores)\n",
        "# else:\n",
        "#     np.save(train_scores_file, np.array(train_scores))\n",
        "\n",
        "# if os.path.exists(test_scores_file):\n",
        "#     existing_test_scores = np.load(test_scores_file)\n",
        "#     updated_test_scores = np.concatenate((existing_test_scores, test_scores))\n",
        "#     np.save(test_scores_file, updated_test_scores)\n",
        "# else:\n",
        "#     np.save(test_scores_file, np.array(test_scores))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qsvc.load(\"/content/drive/MyDrive/Quantum_Studies_phd/PhD/QML_Genom/QSVC_PauliFeatureMap_epoch_1\")"
      ],
      "metadata": {
        "id": "9i5juD0BDFXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6rwoxIsDcxx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "predictions = qsvc.predict(test_sequences[:4000])\n",
        "true_labels = test_labels[:4000]\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate Precision and Recall\n",
        "precision = precision_score(true_labels, predictions)\n",
        "recall = recall_score(true_labels, predictions)\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Calculate F1-Score\n",
        "f1 = f1_score(true_labels, predictions)\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Calculate ROC-AUC Score\n",
        "# Since it's a binary classification, directly pass the true labels and predictions\n",
        "roc_auc = roc_auc_score(true_labels, predictions)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "# Generate a full classification report\n",
        "report = classification_report(true_labels, predictions)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNlCOJZb0DbPf0dvV/zOxMp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}